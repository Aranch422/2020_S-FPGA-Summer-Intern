{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 필요한 모듈 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST 데이터 불러오기\n",
    "최종적으로\n",
    "- ```train_images```의 shape는 $\\left(60000, 28, 28\\right) \\rightarrow \\left(60000, 28, 28, 1\\right) \\rightarrow \\left(60000, 32, 32, 1\\right)$\n",
    "- ```test_lmages```의 shape는 $\\left(10000, 28, 28\\right) \\rightarrow \\left(10000, 28, 28, 1\\right) \\rightarrow \\left(10000, 32, 32, 1\\right)$\n",
    "\n",
    "이 됩니다. 이 과정은 keras에서 구성될 LeNet-5의 input shape를 맞추기 위함입니다. 특히 마지막 단계에서 $\\left(28, 28, 1\\right) \\rightarrow \\left(32, 32, 1\\right)$로의 zero padding이 이루어집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "train_images = np.pad(train_images, ((0,0),(2,2),(2,2),(0,0)), mode=\"constant\")\n",
    "test_images = np.pad(test_images, ((0,0),(2,2),(2,2),(0,0)), mode=\"constant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 네트워크 구성하기\n",
    "keras로 LeNet-5를 구성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Conv2D(6, 5, activation=\"tanh\", input_shape=(32, 32, 1)))\n",
    "model.add(layers.AveragePooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(layers.Conv2D(16, 5, activation=\"tanh\"))\n",
    "model.add(layers.AveragePooling2D(pool_size=(2,2), strides=2))\n",
    "model.add(layers.Conv2D(120, 5, activation=\"tanh\"))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(84, activation=\"tanh\"))\n",
    "model.add(layers.Dense(10, activation=\"softmax\"))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델 학습하기\n",
    "위에서 구성된 모델을 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 중간 레이어 값 확인\n",
    "```ifMap```이 0번째 layer에 입력된 후, ```l```번째 layer의 output featuer map을 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intermediate(l, ifMap):\n",
    "    intermediateModel = models.Model(inputs=model.input,outputs=model.layers[l].output)\n",
    "    return intermediateModel.predict(ifMap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1\n",
    "intermediate(7, test_images[idx].reshape(1, 32, 32, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(model.get_weights()[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 저장하기\n",
    "```pickle```모듈을 이용하여 MNIST ```test_images```, ```test_images```와 모델이 학습한 값 ```model.get_weights()```를 별도의 파일로 저장합니다. 이 파일들은 PYNQ-Z2에서 다시 사용됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_images\", \"wb\") as file:\n",
    "    pickle.dump(test_images, file)\n",
    "    \n",
    "with open(\"test_labels\", \"wb\") as file:\n",
    "    pickle.dump(test_labels, file)\n",
    "    \n",
    "with open(\"weight\", \"wb\") as file:\n",
    "    pickle.dump(model.get_weights(), file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
